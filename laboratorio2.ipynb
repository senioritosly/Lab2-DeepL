{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2\n",
    "Javier Ramirez - 21600\n",
    "\n",
    "Mario Cristales - 21631"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data into a DataFrame\n",
    "df = pd.read_csv('movie_statistic_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Procesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_averageRating    0\n",
      "movie_numerOfVotes     0\n",
      "approval_Index         0\n",
      "Production budget $    0\n",
      "Domestic gross $       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select features and target\n",
    "features = ['movie_averageRating', 'movie_numerOfVotes', 'approval_Index', 'Production budget $', 'Domestic gross $']\n",
    "target = 'Worldwide gross $'\n",
    "\n",
    "# Verificar valores faltantes\n",
    "print(df[features].isna().sum())\n",
    "\n",
    "# Reemplazar valores faltantes con la media\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[features] = imputer.fit_transform(df[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar características\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df[features])\n",
    "\n",
    "# Normalizar la variable objetivo\n",
    "y = df[target].values.reshape(-1, 1)\n",
    "y_scaler = StandardScaler()\n",
    "y = y_scaler.fit_transform(y).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X,\n",
    "  y,\n",
    "  test_size=0.20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo #1: Regularizacion L2, con activacion Relu y 1 capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Network 1: Simple Dense Network with L2 regularization\n",
    "model1 = Sequential([\n",
    "    Dense(64, input_shape=(X_train.shape[1],), activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo #2: 3 capas y activacion tanh, usando regularizacion dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network 2: Network with more layers and different activations, with Dropout regularization\n",
    "model2 = Sequential([\n",
    "    Dense(128, input_shape=(X_train.shape[1],), activation=\"tanh\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='tanh'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='tanh'),\n",
    "    Dropout(0.5),  # Adding an additional layer\n",
    "    Dense(16, activation='tanh'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo #3: 4 capas, activacion relu y regularizacion por batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network 3: Network with Batch Normalization and different activation functions\n",
    "model3 = Sequential([\n",
    "    Dense(256, input_shape=(X_train.shape[1],), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),  # Adding an additional layer\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile models\n",
    "model1.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "model3.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "88/88 - 4s - 41ms/step - loss: 0.8525 - mae: 0.2647 - val_loss: 0.5372 - val_mae: 0.1742\n",
      "Epoch 2/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.4122 - mae: 0.1535 - val_loss: 0.3926 - val_mae: 0.1569\n",
      "Epoch 3/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.3279 - mae: 0.1490 - val_loss: 0.3281 - val_mae: 0.1543\n",
      "Epoch 4/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2779 - mae: 0.1457 - val_loss: 0.2863 - val_mae: 0.1490\n",
      "Epoch 5/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2445 - mae: 0.1451 - val_loss: 0.2605 - val_mae: 0.1592\n",
      "Epoch 6/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2246 - mae: 0.1473 - val_loss: 0.2406 - val_mae: 0.1424\n",
      "Epoch 7/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.2035 - mae: 0.1456 - val_loss: 0.2351 - val_mae: 0.1476\n",
      "Epoch 8/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1909 - mae: 0.1484 - val_loss: 0.2141 - val_mae: 0.1506\n",
      "Epoch 9/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1771 - mae: 0.1452 - val_loss: 0.1984 - val_mae: 0.1475\n",
      "Epoch 10/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1672 - mae: 0.1476 - val_loss: 0.1869 - val_mae: 0.1488\n",
      "Epoch 11/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1579 - mae: 0.1429 - val_loss: 0.1780 - val_mae: 0.1462\n",
      "Epoch 12/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1504 - mae: 0.1444 - val_loss: 0.1723 - val_mae: 0.1466\n",
      "Epoch 13/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1440 - mae: 0.1429 - val_loss: 0.1691 - val_mae: 0.1432\n",
      "Epoch 14/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1371 - mae: 0.1421 - val_loss: 0.1602 - val_mae: 0.1461\n",
      "Epoch 15/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1366 - mae: 0.1461 - val_loss: 0.1691 - val_mae: 0.1490\n",
      "Epoch 16/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1291 - mae: 0.1441 - val_loss: 0.1538 - val_mae: 0.1521\n",
      "Epoch 17/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1251 - mae: 0.1436 - val_loss: 0.1522 - val_mae: 0.1463\n",
      "Epoch 18/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1217 - mae: 0.1428 - val_loss: 0.1494 - val_mae: 0.1405\n",
      "Epoch 19/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1234 - mae: 0.1443 - val_loss: 0.1557 - val_mae: 0.1556\n",
      "Epoch 20/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1156 - mae: 0.1430 - val_loss: 0.1444 - val_mae: 0.1430\n",
      "Epoch 21/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1143 - mae: 0.1422 - val_loss: 0.1382 - val_mae: 0.1472\n",
      "Epoch 22/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1110 - mae: 0.1418 - val_loss: 0.1383 - val_mae: 0.1420\n",
      "Epoch 23/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1094 - mae: 0.1418 - val_loss: 0.1362 - val_mae: 0.1428\n",
      "Epoch 24/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1085 - mae: 0.1415 - val_loss: 0.1315 - val_mae: 0.1521\n",
      "Epoch 25/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1085 - mae: 0.1421 - val_loss: 0.1327 - val_mae: 0.1458\n",
      "Epoch 26/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1038 - mae: 0.1394 - val_loss: 0.1403 - val_mae: 0.1407\n",
      "Epoch 27/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1030 - mae: 0.1422 - val_loss: 0.1284 - val_mae: 0.1513\n",
      "Epoch 28/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1037 - mae: 0.1455 - val_loss: 0.1295 - val_mae: 0.1538\n",
      "Epoch 29/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1008 - mae: 0.1432 - val_loss: 0.1256 - val_mae: 0.1407\n",
      "Epoch 30/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0987 - mae: 0.1406 - val_loss: 0.1322 - val_mae: 0.1471\n",
      "Epoch 31/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0978 - mae: 0.1388 - val_loss: 0.1258 - val_mae: 0.1518\n",
      "Epoch 32/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0984 - mae: 0.1418 - val_loss: 0.1226 - val_mae: 0.1440\n",
      "Epoch 33/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0980 - mae: 0.1410 - val_loss: 0.1240 - val_mae: 0.1494\n",
      "Epoch 34/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0968 - mae: 0.1405 - val_loss: 0.1442 - val_mae: 0.1428\n",
      "Epoch 35/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0980 - mae: 0.1449 - val_loss: 0.1214 - val_mae: 0.1416\n",
      "Epoch 36/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0957 - mae: 0.1410 - val_loss: 0.1232 - val_mae: 0.1472\n",
      "Epoch 37/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0956 - mae: 0.1384 - val_loss: 0.1224 - val_mae: 0.1485\n",
      "Epoch 38/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0932 - mae: 0.1408 - val_loss: 0.1346 - val_mae: 0.1473\n",
      "Epoch 39/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0946 - mae: 0.1416 - val_loss: 0.1211 - val_mae: 0.1538\n",
      "Epoch 40/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0988 - mae: 0.1453 - val_loss: 0.1209 - val_mae: 0.1473\n",
      "Epoch 41/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0997 - mae: 0.1471 - val_loss: 0.1213 - val_mae: 0.1537\n",
      "Epoch 42/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0953 - mae: 0.1437 - val_loss: 0.1212 - val_mae: 0.1406\n",
      "Epoch 43/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0918 - mae: 0.1410 - val_loss: 0.1320 - val_mae: 0.1453\n",
      "Epoch 44/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0923 - mae: 0.1416 - val_loss: 0.1282 - val_mae: 0.1434\n",
      "Epoch 45/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0921 - mae: 0.1382 - val_loss: 0.1402 - val_mae: 0.1420\n",
      "Epoch 46/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0943 - mae: 0.1441 - val_loss: 0.1183 - val_mae: 0.1446\n",
      "Epoch 47/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0922 - mae: 0.1401 - val_loss: 0.1208 - val_mae: 0.1404\n",
      "Epoch 48/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0934 - mae: 0.1423 - val_loss: 0.1176 - val_mae: 0.1451\n",
      "Epoch 49/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0912 - mae: 0.1408 - val_loss: 0.1215 - val_mae: 0.1520\n",
      "Epoch 50/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0942 - mae: 0.1462 - val_loss: 0.1182 - val_mae: 0.1442\n",
      "Epoch 51/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0918 - mae: 0.1410 - val_loss: 0.1183 - val_mae: 0.1432\n",
      "Epoch 52/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0925 - mae: 0.1394 - val_loss: 0.1261 - val_mae: 0.1448\n",
      "Epoch 53/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0936 - mae: 0.1431 - val_loss: 0.1269 - val_mae: 0.1641\n",
      "Epoch 54/100\n",
      "88/88 - 0s - 3ms/step - loss: 0.0922 - mae: 0.1436 - val_loss: 0.1166 - val_mae: 0.1424\n",
      "Epoch 55/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0913 - mae: 0.1440 - val_loss: 0.1183 - val_mae: 0.1481\n",
      "Epoch 56/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0915 - mae: 0.1404 - val_loss: 0.1215 - val_mae: 0.1500\n",
      "Epoch 57/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0900 - mae: 0.1387 - val_loss: 0.1183 - val_mae: 0.1545\n",
      "Epoch 58/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0893 - mae: 0.1382 - val_loss: 0.1200 - val_mae: 0.1416\n",
      "Epoch 59/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0910 - mae: 0.1409 - val_loss: 0.1165 - val_mae: 0.1440\n",
      "Epoch 60/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0928 - mae: 0.1442 - val_loss: 0.1184 - val_mae: 0.1426\n",
      "Epoch 61/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0915 - mae: 0.1411 - val_loss: 0.1187 - val_mae: 0.1454\n",
      "Epoch 62/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0914 - mae: 0.1410 - val_loss: 0.1285 - val_mae: 0.1522\n",
      "Epoch 63/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0927 - mae: 0.1470 - val_loss: 0.1215 - val_mae: 0.1678\n",
      "Epoch 64/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0917 - mae: 0.1414 - val_loss: 0.1238 - val_mae: 0.1499\n",
      "Epoch 65/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0883 - mae: 0.1406 - val_loss: 0.1152 - val_mae: 0.1416\n",
      "Epoch 66/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0886 - mae: 0.1381 - val_loss: 0.1314 - val_mae: 0.1542\n",
      "Epoch 67/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0908 - mae: 0.1429 - val_loss: 0.1220 - val_mae: 0.1412\n",
      "Epoch 68/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0892 - mae: 0.1388 - val_loss: 0.1197 - val_mae: 0.1437\n",
      "Epoch 69/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0932 - mae: 0.1426 - val_loss: 0.1206 - val_mae: 0.1494\n",
      "Epoch 70/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0909 - mae: 0.1424 - val_loss: 0.1178 - val_mae: 0.1434\n",
      "Epoch 71/100\n",
      "88/88 - 0s - 6ms/step - loss: 0.0881 - mae: 0.1400 - val_loss: 0.1163 - val_mae: 0.1465\n",
      "Epoch 72/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0891 - mae: 0.1395 - val_loss: 0.1203 - val_mae: 0.1493\n",
      "Epoch 73/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0905 - mae: 0.1398 - val_loss: 0.1227 - val_mae: 0.1448\n",
      "Epoch 74/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0901 - mae: 0.1424 - val_loss: 0.1223 - val_mae: 0.1418\n",
      "Epoch 75/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0906 - mae: 0.1391 - val_loss: 0.1179 - val_mae: 0.1412\n",
      "Epoch 76/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0900 - mae: 0.1405 - val_loss: 0.1259 - val_mae: 0.1425\n",
      "Epoch 77/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0885 - mae: 0.1424 - val_loss: 0.1239 - val_mae: 0.1515\n",
      "Epoch 78/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0915 - mae: 0.1417 - val_loss: 0.1206 - val_mae: 0.1430\n",
      "Epoch 79/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0903 - mae: 0.1420 - val_loss: 0.1189 - val_mae: 0.1475\n",
      "Epoch 80/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0881 - mae: 0.1387 - val_loss: 0.1155 - val_mae: 0.1511\n",
      "Epoch 81/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0937 - mae: 0.1460 - val_loss: 0.1267 - val_mae: 0.1420\n",
      "Epoch 82/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0898 - mae: 0.1449 - val_loss: 0.1196 - val_mae: 0.1455\n",
      "Epoch 83/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0878 - mae: 0.1428 - val_loss: 0.1157 - val_mae: 0.1463\n",
      "Epoch 84/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0906 - mae: 0.1459 - val_loss: 0.1224 - val_mae: 0.1411\n",
      "Epoch 85/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0890 - mae: 0.1404 - val_loss: 0.1271 - val_mae: 0.1516\n",
      "Epoch 86/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0904 - mae: 0.1472 - val_loss: 0.1188 - val_mae: 0.1408\n",
      "Epoch 87/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0871 - mae: 0.1383 - val_loss: 0.1393 - val_mae: 0.1423\n",
      "Epoch 88/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0906 - mae: 0.1440 - val_loss: 0.1218 - val_mae: 0.1393\n",
      "Epoch 89/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0904 - mae: 0.1399 - val_loss: 0.1178 - val_mae: 0.1547\n",
      "Epoch 90/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0882 - mae: 0.1422 - val_loss: 0.1160 - val_mae: 0.1402\n",
      "Epoch 91/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0875 - mae: 0.1405 - val_loss: 0.1202 - val_mae: 0.1403\n",
      "Epoch 92/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0877 - mae: 0.1404 - val_loss: 0.1201 - val_mae: 0.1446\n",
      "Epoch 93/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0880 - mae: 0.1396 - val_loss: 0.1242 - val_mae: 0.1461\n",
      "Epoch 94/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0877 - mae: 0.1412 - val_loss: 0.1238 - val_mae: 0.1415\n",
      "Epoch 95/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0911 - mae: 0.1475 - val_loss: 0.1142 - val_mae: 0.1423\n",
      "Epoch 96/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0877 - mae: 0.1384 - val_loss: 0.1153 - val_mae: 0.1527\n",
      "Epoch 97/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0884 - mae: 0.1417 - val_loss: 0.1151 - val_mae: 0.1508\n",
      "Epoch 98/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0879 - mae: 0.1411 - val_loss: 0.1250 - val_mae: 0.1400\n",
      "Epoch 99/100\n",
      "88/88 - 1s - 8ms/step - loss: 0.0923 - mae: 0.1434 - val_loss: 0.1158 - val_mae: 0.1601\n",
      "Epoch 100/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.0909 - mae: 0.1433 - val_loss: 0.1179 - val_mae: 0.1432\n",
      "Epoch 1/100\n",
      "88/88 - 5s - 52ms/step - loss: 0.7813 - mae: 0.5487 - val_loss: 0.6436 - val_mae: 0.4044\n",
      "Epoch 2/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.5761 - mae: 0.4321 - val_loss: 0.6028 - val_mae: 0.3762\n",
      "Epoch 3/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.5015 - mae: 0.3999 - val_loss: 0.5428 - val_mae: 0.2981\n",
      "Epoch 4/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.4917 - mae: 0.3793 - val_loss: 0.5385 - val_mae: 0.3180\n",
      "Epoch 5/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.4252 - mae: 0.3472 - val_loss: 0.4868 - val_mae: 0.2680\n",
      "Epoch 6/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.3869 - mae: 0.3417 - val_loss: 0.4531 - val_mae: 0.2284\n",
      "Epoch 7/100\n",
      "88/88 - 0s - 6ms/step - loss: 0.3579 - mae: 0.3268 - val_loss: 0.4070 - val_mae: 0.2047\n",
      "Epoch 8/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.3455 - mae: 0.3203 - val_loss: 0.4026 - val_mae: 0.2250\n",
      "Epoch 9/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.3250 - mae: 0.3146 - val_loss: 0.3833 - val_mae: 0.2103\n",
      "Epoch 10/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.3063 - mae: 0.3025 - val_loss: 0.3789 - val_mae: 0.2101\n",
      "Epoch 11/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.3030 - mae: 0.3062 - val_loss: 0.3818 - val_mae: 0.2420\n",
      "Epoch 12/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.2993 - mae: 0.3084 - val_loss: 0.3608 - val_mae: 0.2090\n",
      "Epoch 13/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2996 - mae: 0.3050 - val_loss: 0.3781 - val_mae: 0.2067\n",
      "Epoch 14/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.2740 - mae: 0.2901 - val_loss: 0.3635 - val_mae: 0.2137\n",
      "Epoch 15/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2793 - mae: 0.3006 - val_loss: 0.3325 - val_mae: 0.2023\n",
      "Epoch 16/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2725 - mae: 0.2985 - val_loss: 0.3346 - val_mae: 0.2334\n",
      "Epoch 17/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2567 - mae: 0.2870 - val_loss: 0.3440 - val_mae: 0.2171\n",
      "Epoch 18/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2561 - mae: 0.2879 - val_loss: 0.3354 - val_mae: 0.2255\n",
      "Epoch 19/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2584 - mae: 0.2875 - val_loss: 0.3214 - val_mae: 0.2025\n",
      "Epoch 20/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2430 - mae: 0.2832 - val_loss: 0.3241 - val_mae: 0.2443\n",
      "Epoch 21/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.2585 - mae: 0.2915 - val_loss: 0.3202 - val_mae: 0.2173\n",
      "Epoch 22/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.2515 - mae: 0.2780 - val_loss: 0.3038 - val_mae: 0.2148\n",
      "Epoch 23/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2438 - mae: 0.2791 - val_loss: 0.3251 - val_mae: 0.2436\n",
      "Epoch 24/100\n",
      "88/88 - 1s - 10ms/step - loss: 0.2419 - mae: 0.2835 - val_loss: 0.3170 - val_mae: 0.2355\n",
      "Epoch 25/100\n",
      "88/88 - 1s - 7ms/step - loss: 0.2364 - mae: 0.2714 - val_loss: 0.3138 - val_mae: 0.2296\n",
      "Epoch 26/100\n",
      "88/88 - 1s - 7ms/step - loss: 0.2212 - mae: 0.2659 - val_loss: 0.3040 - val_mae: 0.2269\n",
      "Epoch 27/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.2333 - mae: 0.2670 - val_loss: 0.2922 - val_mae: 0.2131\n",
      "Epoch 28/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2198 - mae: 0.2574 - val_loss: 0.3008 - val_mae: 0.2310\n",
      "Epoch 29/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2206 - mae: 0.2599 - val_loss: 0.3153 - val_mae: 0.2457\n",
      "Epoch 30/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2224 - mae: 0.2684 - val_loss: 0.2998 - val_mae: 0.2509\n",
      "Epoch 31/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2094 - mae: 0.2638 - val_loss: 0.3143 - val_mae: 0.2278\n",
      "Epoch 32/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2129 - mae: 0.2581 - val_loss: 0.2880 - val_mae: 0.2289\n",
      "Epoch 33/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2265 - mae: 0.2631 - val_loss: 0.3244 - val_mae: 0.2964\n",
      "Epoch 34/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2097 - mae: 0.2596 - val_loss: 0.2994 - val_mae: 0.2225\n",
      "Epoch 35/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.2028 - mae: 0.2524 - val_loss: 0.2836 - val_mae: 0.1910\n",
      "Epoch 36/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.2112 - mae: 0.2584 - val_loss: 0.3044 - val_mae: 0.2770\n",
      "Epoch 37/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2161 - mae: 0.2612 - val_loss: 0.2666 - val_mae: 0.2081\n",
      "Epoch 38/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2073 - mae: 0.2568 - val_loss: 0.2822 - val_mae: 0.2216\n",
      "Epoch 39/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1912 - mae: 0.2463 - val_loss: 0.2992 - val_mae: 0.2814\n",
      "Epoch 40/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.2065 - mae: 0.2545 - val_loss: 0.2963 - val_mae: 0.2446\n",
      "Epoch 41/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1864 - mae: 0.2447 - val_loss: 0.2635 - val_mae: 0.2252\n",
      "Epoch 42/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.2009 - mae: 0.2490 - val_loss: 0.2807 - val_mae: 0.2437\n",
      "Epoch 43/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1796 - mae: 0.2439 - val_loss: 0.2844 - val_mae: 0.2238\n",
      "Epoch 44/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.2004 - mae: 0.2567 - val_loss: 0.2871 - val_mae: 0.2577\n",
      "Epoch 45/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1839 - mae: 0.2417 - val_loss: 0.2692 - val_mae: 0.1913\n",
      "Epoch 46/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1888 - mae: 0.2392 - val_loss: 0.2801 - val_mae: 0.2220\n",
      "Epoch 47/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1849 - mae: 0.2417 - val_loss: 0.2982 - val_mae: 0.2732\n",
      "Epoch 48/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1945 - mae: 0.2443 - val_loss: 0.2766 - val_mae: 0.2257\n",
      "Epoch 49/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1830 - mae: 0.2458 - val_loss: 0.2994 - val_mae: 0.2682\n",
      "Epoch 50/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1913 - mae: 0.2450 - val_loss: 0.2727 - val_mae: 0.2226\n",
      "Epoch 51/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1763 - mae: 0.2355 - val_loss: 0.2819 - val_mae: 0.2674\n",
      "Epoch 52/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1887 - mae: 0.2362 - val_loss: 0.2591 - val_mae: 0.2303\n",
      "Epoch 53/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1817 - mae: 0.2346 - val_loss: 0.2863 - val_mae: 0.2469\n",
      "Epoch 54/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1947 - mae: 0.2463 - val_loss: 0.2681 - val_mae: 0.2257\n",
      "Epoch 55/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1917 - mae: 0.2454 - val_loss: 0.2743 - val_mae: 0.2454\n",
      "Epoch 56/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1787 - mae: 0.2371 - val_loss: 0.2695 - val_mae: 0.2330\n",
      "Epoch 57/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1887 - mae: 0.2338 - val_loss: 0.2721 - val_mae: 0.2714\n",
      "Epoch 58/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1761 - mae: 0.2316 - val_loss: 0.2622 - val_mae: 0.1984\n",
      "Epoch 59/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1806 - mae: 0.2310 - val_loss: 0.2428 - val_mae: 0.2019\n",
      "Epoch 60/100\n",
      "88/88 - 1s - 7ms/step - loss: 0.1667 - mae: 0.2299 - val_loss: 0.2655 - val_mae: 0.2389\n",
      "Epoch 61/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1631 - mae: 0.2300 - val_loss: 0.2429 - val_mae: 0.2074\n",
      "Epoch 62/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1698 - mae: 0.2318 - val_loss: 0.2610 - val_mae: 0.2284\n",
      "Epoch 63/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1741 - mae: 0.2307 - val_loss: 0.2536 - val_mae: 0.2298\n",
      "Epoch 64/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1742 - mae: 0.2320 - val_loss: 0.2329 - val_mae: 0.2211\n",
      "Epoch 65/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1707 - mae: 0.2248 - val_loss: 0.2724 - val_mae: 0.2166\n",
      "Epoch 66/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1865 - mae: 0.2313 - val_loss: 0.2543 - val_mae: 0.2350\n",
      "Epoch 67/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1695 - mae: 0.2294 - val_loss: 0.2473 - val_mae: 0.2231\n",
      "Epoch 68/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1663 - mae: 0.2266 - val_loss: 0.2482 - val_mae: 0.2154\n",
      "Epoch 69/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1645 - mae: 0.2217 - val_loss: 0.2496 - val_mae: 0.2277\n",
      "Epoch 70/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1632 - mae: 0.2210 - val_loss: 0.2336 - val_mae: 0.2124\n",
      "Epoch 71/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1694 - mae: 0.2287 - val_loss: 0.2412 - val_mae: 0.2184\n",
      "Epoch 72/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1702 - mae: 0.2249 - val_loss: 0.2563 - val_mae: 0.2048\n",
      "Epoch 73/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1679 - mae: 0.2197 - val_loss: 0.2524 - val_mae: 0.1990\n",
      "Epoch 74/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1666 - mae: 0.2260 - val_loss: 0.2611 - val_mae: 0.2272\n",
      "Epoch 75/100\n",
      "88/88 - 1s - 10ms/step - loss: 0.1494 - mae: 0.2126 - val_loss: 0.2555 - val_mae: 0.2006\n",
      "Epoch 76/100\n",
      "88/88 - 1s - 11ms/step - loss: 0.1642 - mae: 0.2211 - val_loss: 0.2613 - val_mae: 0.2636\n",
      "Epoch 77/100\n",
      "88/88 - 1s - 7ms/step - loss: 0.1785 - mae: 0.2283 - val_loss: 0.2333 - val_mae: 0.2062\n",
      "Epoch 78/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1592 - mae: 0.2170 - val_loss: 0.2468 - val_mae: 0.2142\n",
      "Epoch 79/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1685 - mae: 0.2213 - val_loss: 0.2347 - val_mae: 0.2322\n",
      "Epoch 80/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1622 - mae: 0.2211 - val_loss: 0.2742 - val_mae: 0.2377\n",
      "Epoch 81/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1610 - mae: 0.2200 - val_loss: 0.2341 - val_mae: 0.1970\n",
      "Epoch 82/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1838 - mae: 0.2279 - val_loss: 0.2575 - val_mae: 0.2118\n",
      "Epoch 83/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1584 - mae: 0.2141 - val_loss: 0.2496 - val_mae: 0.2045\n",
      "Epoch 84/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1630 - mae: 0.2132 - val_loss: 0.2332 - val_mae: 0.2110\n",
      "Epoch 85/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1602 - mae: 0.2158 - val_loss: 0.2786 - val_mae: 0.2107\n",
      "Epoch 86/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1726 - mae: 0.2191 - val_loss: 0.2515 - val_mae: 0.2303\n",
      "Epoch 87/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1596 - mae: 0.2153 - val_loss: 0.3010 - val_mae: 0.2489\n",
      "Epoch 88/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1751 - mae: 0.2277 - val_loss: 0.2614 - val_mae: 0.2294\n",
      "Epoch 89/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1597 - mae: 0.2101 - val_loss: 0.2274 - val_mae: 0.2042\n",
      "Epoch 90/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1626 - mae: 0.2146 - val_loss: 0.2253 - val_mae: 0.1904\n",
      "Epoch 91/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1579 - mae: 0.2141 - val_loss: 0.2325 - val_mae: 0.2199\n",
      "Epoch 92/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1568 - mae: 0.2200 - val_loss: 0.2433 - val_mae: 0.2188\n",
      "Epoch 93/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1551 - mae: 0.2119 - val_loss: 0.2388 - val_mae: 0.2187\n",
      "Epoch 94/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1611 - mae: 0.2137 - val_loss: 0.2242 - val_mae: 0.1876\n",
      "Epoch 95/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1534 - mae: 0.2096 - val_loss: 0.2219 - val_mae: 0.1964\n",
      "Epoch 96/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1507 - mae: 0.2052 - val_loss: 0.2280 - val_mae: 0.2056\n",
      "Epoch 97/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1588 - mae: 0.2186 - val_loss: 0.2255 - val_mae: 0.2221\n",
      "Epoch 98/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1467 - mae: 0.2107 - val_loss: 0.2153 - val_mae: 0.1970\n",
      "Epoch 99/100\n",
      "88/88 - 0s - 4ms/step - loss: 0.1470 - mae: 0.2060 - val_loss: 0.2643 - val_mae: 0.2464\n",
      "Epoch 100/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1514 - mae: 0.2135 - val_loss: 0.2246 - val_mae: 0.2014\n",
      "Epoch 1/100\n",
      "88/88 - 7s - 81ms/step - loss: 0.3080 - mae: 0.3257 - val_loss: 0.8467 - val_mae: 0.4518\n",
      "Epoch 2/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1909 - mae: 0.2514 - val_loss: 0.7365 - val_mae: 0.4049\n",
      "Epoch 3/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1899 - mae: 0.2440 - val_loss: 0.4492 - val_mae: 0.3149\n",
      "Epoch 4/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1440 - mae: 0.2171 - val_loss: 0.2092 - val_mae: 0.2133\n",
      "Epoch 5/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1341 - mae: 0.2110 - val_loss: 0.1300 - val_mae: 0.1829\n",
      "Epoch 6/100\n",
      "88/88 - 1s - 8ms/step - loss: 0.1437 - mae: 0.2088 - val_loss: 0.1160 - val_mae: 0.1782\n",
      "Epoch 7/100\n",
      "88/88 - 1s - 8ms/step - loss: 0.1089 - mae: 0.1927 - val_loss: 0.1531 - val_mae: 0.1682\n",
      "Epoch 8/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1424 - mae: 0.2025 - val_loss: 0.1565 - val_mae: 0.1953\n",
      "Epoch 9/100\n",
      "88/88 - 0s - 6ms/step - loss: 0.1528 - mae: 0.2008 - val_loss: 0.1017 - val_mae: 0.1738\n",
      "Epoch 10/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1383 - mae: 0.2039 - val_loss: 0.1452 - val_mae: 0.1818\n",
      "Epoch 11/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1211 - mae: 0.1897 - val_loss: 0.1402 - val_mae: 0.1681\n",
      "Epoch 12/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1334 - mae: 0.1947 - val_loss: 0.1636 - val_mae: 0.1880\n",
      "Epoch 13/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1144 - mae: 0.1811 - val_loss: 0.1055 - val_mae: 0.1526\n",
      "Epoch 14/100\n",
      "88/88 - 0s - 6ms/step - loss: 0.1008 - mae: 0.1774 - val_loss: 0.1226 - val_mae: 0.1596\n",
      "Epoch 15/100\n",
      "88/88 - 1s - 7ms/step - loss: 0.0963 - mae: 0.1726 - val_loss: 0.1308 - val_mae: 0.1622\n",
      "Epoch 16/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1013 - mae: 0.1709 - val_loss: 0.1338 - val_mae: 0.1571\n",
      "Epoch 17/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1256 - mae: 0.1870 - val_loss: 0.1706 - val_mae: 0.1728\n",
      "Epoch 18/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1248 - mae: 0.1781 - val_loss: 0.1254 - val_mae: 0.1566\n",
      "Epoch 19/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1021 - mae: 0.1727 - val_loss: 0.1197 - val_mae: 0.1568\n",
      "Epoch 20/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1144 - mae: 0.1762 - val_loss: 0.1152 - val_mae: 0.1526\n",
      "Epoch 21/100\n",
      "88/88 - 0s - 6ms/step - loss: 0.1074 - mae: 0.1681 - val_loss: 0.1499 - val_mae: 0.1701\n",
      "Epoch 22/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1178 - mae: 0.1718 - val_loss: 0.1577 - val_mae: 0.1684\n",
      "Epoch 23/100\n",
      "88/88 - 0s - 6ms/step - loss: 0.1151 - mae: 0.1773 - val_loss: 0.1396 - val_mae: 0.1562\n",
      "Epoch 24/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1200 - mae: 0.1810 - val_loss: 0.1381 - val_mae: 0.1763\n",
      "Epoch 25/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1050 - mae: 0.1703 - val_loss: 0.1741 - val_mae: 0.1717\n",
      "Epoch 26/100\n",
      "88/88 - 1s - 7ms/step - loss: 0.1178 - mae: 0.1757 - val_loss: 0.1664 - val_mae: 0.1646\n",
      "Epoch 27/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1142 - mae: 0.1746 - val_loss: 0.1889 - val_mae: 0.1663\n",
      "Epoch 28/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1131 - mae: 0.1759 - val_loss: 0.1354 - val_mae: 0.1664\n",
      "Epoch 29/100\n",
      "88/88 - 1s - 7ms/step - loss: 0.0863 - mae: 0.1632 - val_loss: 0.1284 - val_mae: 0.1677\n",
      "Epoch 30/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0925 - mae: 0.1618 - val_loss: 0.1094 - val_mae: 0.1538\n",
      "Epoch 31/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0820 - mae: 0.1567 - val_loss: 0.1015 - val_mae: 0.1410\n",
      "Epoch 32/100\n",
      "88/88 - 0s - 6ms/step - loss: 0.0966 - mae: 0.1644 - val_loss: 0.1180 - val_mae: 0.1502\n",
      "Epoch 33/100\n",
      "88/88 - 1s - 7ms/step - loss: 0.1067 - mae: 0.1670 - val_loss: 0.1436 - val_mae: 0.1669\n",
      "Epoch 34/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1004 - mae: 0.1660 - val_loss: 0.1366 - val_mae: 0.1717\n",
      "Epoch 35/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0954 - mae: 0.1662 - val_loss: 0.1281 - val_mae: 0.1608\n",
      "Epoch 36/100\n",
      "88/88 - 0s - 6ms/step - loss: 0.0930 - mae: 0.1626 - val_loss: 0.1420 - val_mae: 0.1718\n",
      "Epoch 37/100\n",
      "88/88 - 1s - 7ms/step - loss: 0.1074 - mae: 0.1713 - val_loss: 0.1365 - val_mae: 0.1758\n",
      "Epoch 38/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0814 - mae: 0.1582 - val_loss: 0.1209 - val_mae: 0.1514\n",
      "Epoch 39/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0862 - mae: 0.1543 - val_loss: 0.1148 - val_mae: 0.1632\n",
      "Epoch 40/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0905 - mae: 0.1539 - val_loss: 0.1430 - val_mae: 0.1654\n",
      "Epoch 41/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0898 - mae: 0.1557 - val_loss: 0.1267 - val_mae: 0.1507\n",
      "Epoch 42/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.1106 - mae: 0.1667 - val_loss: 0.1973 - val_mae: 0.1762\n",
      "Epoch 43/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0993 - mae: 0.1672 - val_loss: 0.1509 - val_mae: 0.1622\n",
      "Epoch 44/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0830 - mae: 0.1524 - val_loss: 0.1232 - val_mae: 0.1537\n",
      "Epoch 45/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0920 - mae: 0.1587 - val_loss: 0.1195 - val_mae: 0.1472\n",
      "Epoch 46/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0843 - mae: 0.1583 - val_loss: 0.1016 - val_mae: 0.1455\n",
      "Epoch 47/100\n",
      "88/88 - 1s - 7ms/step - loss: 0.0963 - mae: 0.1646 - val_loss: 0.2084 - val_mae: 0.1886\n",
      "Epoch 48/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.1057 - mae: 0.1671 - val_loss: 0.1306 - val_mae: 0.1542\n",
      "Epoch 49/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0925 - mae: 0.1633 - val_loss: 0.1337 - val_mae: 0.1542\n",
      "Epoch 50/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0869 - mae: 0.1622 - val_loss: 0.1620 - val_mae: 0.1635\n",
      "Epoch 51/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0884 - mae: 0.1569 - val_loss: 0.1450 - val_mae: 0.1550\n",
      "Epoch 52/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0916 - mae: 0.1523 - val_loss: 0.1251 - val_mae: 0.1500\n",
      "Epoch 53/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0814 - mae: 0.1527 - val_loss: 0.1339 - val_mae: 0.1577\n",
      "Epoch 54/100\n",
      "88/88 - 1s - 8ms/step - loss: 0.0799 - mae: 0.1511 - val_loss: 0.1205 - val_mae: 0.1674\n",
      "Epoch 55/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0970 - mae: 0.1612 - val_loss: 0.1103 - val_mae: 0.1504\n",
      "Epoch 56/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0954 - mae: 0.1544 - val_loss: 0.1445 - val_mae: 0.1595\n",
      "Epoch 57/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0854 - mae: 0.1510 - val_loss: 0.1263 - val_mae: 0.1608\n",
      "Epoch 58/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0711 - mae: 0.1473 - val_loss: 0.1188 - val_mae: 0.1576\n",
      "Epoch 59/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0923 - mae: 0.1561 - val_loss: 0.1254 - val_mae: 0.1628\n",
      "Epoch 60/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0773 - mae: 0.1510 - val_loss: 0.1209 - val_mae: 0.1648\n",
      "Epoch 61/100\n",
      "88/88 - 1s - 7ms/step - loss: 0.0853 - mae: 0.1524 - val_loss: 0.1124 - val_mae: 0.1548\n",
      "Epoch 62/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0821 - mae: 0.1503 - val_loss: 0.1192 - val_mae: 0.1613\n",
      "Epoch 63/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0772 - mae: 0.1529 - val_loss: 0.1048 - val_mae: 0.1596\n",
      "Epoch 64/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0892 - mae: 0.1532 - val_loss: 0.1259 - val_mae: 0.1656\n",
      "Epoch 65/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0825 - mae: 0.1525 - val_loss: 0.1202 - val_mae: 0.1614\n",
      "Epoch 66/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0774 - mae: 0.1488 - val_loss: 0.1409 - val_mae: 0.1497\n",
      "Epoch 67/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0793 - mae: 0.1500 - val_loss: 0.0967 - val_mae: 0.1408\n",
      "Epoch 68/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0924 - mae: 0.1555 - val_loss: 0.1322 - val_mae: 0.1567\n",
      "Epoch 69/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0877 - mae: 0.1535 - val_loss: 0.1969 - val_mae: 0.1738\n",
      "Epoch 70/100\n",
      "88/88 - 1s - 7ms/step - loss: 0.0959 - mae: 0.1568 - val_loss: 0.1248 - val_mae: 0.1498\n",
      "Epoch 71/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0868 - mae: 0.1534 - val_loss: 0.2094 - val_mae: 0.1718\n",
      "Epoch 72/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0859 - mae: 0.1485 - val_loss: 0.1559 - val_mae: 0.1570\n",
      "Epoch 73/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0803 - mae: 0.1513 - val_loss: 0.1221 - val_mae: 0.1517\n",
      "Epoch 74/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0699 - mae: 0.1442 - val_loss: 0.1739 - val_mae: 0.1732\n",
      "Epoch 75/100\n",
      "88/88 - 0s - 6ms/step - loss: 0.0786 - mae: 0.1499 - val_loss: 0.1623 - val_mae: 0.1679\n",
      "Epoch 76/100\n",
      "88/88 - 1s - 8ms/step - loss: 0.0816 - mae: 0.1479 - val_loss: 0.1552 - val_mae: 0.1611\n",
      "Epoch 77/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0848 - mae: 0.1548 - val_loss: 0.1189 - val_mae: 0.1560\n",
      "Epoch 78/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0806 - mae: 0.1518 - val_loss: 0.0964 - val_mae: 0.1510\n",
      "Epoch 79/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0810 - mae: 0.1509 - val_loss: 0.1321 - val_mae: 0.1568\n",
      "Epoch 80/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0772 - mae: 0.1436 - val_loss: 0.1478 - val_mae: 0.1626\n",
      "Epoch 81/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0837 - mae: 0.1495 - val_loss: 0.1967 - val_mae: 0.1570\n",
      "Epoch 82/100\n",
      "88/88 - 0s - 6ms/step - loss: 0.0885 - mae: 0.1492 - val_loss: 0.1328 - val_mae: 0.1672\n",
      "Epoch 83/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0732 - mae: 0.1445 - val_loss: 0.1018 - val_mae: 0.1459\n",
      "Epoch 84/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0705 - mae: 0.1408 - val_loss: 0.0999 - val_mae: 0.1492\n",
      "Epoch 85/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0644 - mae: 0.1381 - val_loss: 0.1309 - val_mae: 0.1523\n",
      "Epoch 86/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0784 - mae: 0.1495 - val_loss: 0.1053 - val_mae: 0.1484\n",
      "Epoch 87/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0696 - mae: 0.1402 - val_loss: 0.1187 - val_mae: 0.1629\n",
      "Epoch 88/100\n",
      "88/88 - 1s - 6ms/step - loss: 0.0690 - mae: 0.1439 - val_loss: 0.1164 - val_mae: 0.1567\n",
      "Epoch 89/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0712 - mae: 0.1458 - val_loss: 0.1135 - val_mae: 0.1508\n",
      "Epoch 90/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0677 - mae: 0.1430 - val_loss: 0.1633 - val_mae: 0.1716\n",
      "Epoch 91/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0794 - mae: 0.1462 - val_loss: 0.1054 - val_mae: 0.1534\n",
      "Epoch 92/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0683 - mae: 0.1420 - val_loss: 0.1016 - val_mae: 0.1493\n",
      "Epoch 93/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0669 - mae: 0.1426 - val_loss: 0.0960 - val_mae: 0.1445\n",
      "Epoch 94/100\n",
      "88/88 - 0s - 6ms/step - loss: 0.0830 - mae: 0.1465 - val_loss: 0.1104 - val_mae: 0.1535\n",
      "Epoch 95/100\n",
      "88/88 - 0s - 6ms/step - loss: 0.0761 - mae: 0.1468 - val_loss: 0.1350 - val_mae: 0.1599\n",
      "Epoch 96/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0630 - mae: 0.1372 - val_loss: 0.1501 - val_mae: 0.1610\n",
      "Epoch 97/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0708 - mae: 0.1458 - val_loss: 0.1607 - val_mae: 0.1656\n",
      "Epoch 98/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0771 - mae: 0.1482 - val_loss: 0.1349 - val_mae: 0.1727\n",
      "Epoch 99/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0743 - mae: 0.1459 - val_loss: 0.1310 - val_mae: 0.1659\n",
      "Epoch 100/100\n",
      "88/88 - 0s - 5ms/step - loss: 0.0781 - mae: 0.1500 - val_loss: 0.1234 - val_mae: 0.1542\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "history1 = model1.fit(X_train, y_train, epochs=100, validation_split=0.2, batch_size=32, verbose=2)\n",
    "history2 = model2.fit(X_train, y_train, epochs=100, validation_split=0.2, batch_size=32, verbose=2)\n",
    "history3 = model3.fit(X_train, y_train, epochs=100, validation_split=0.2, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Evaluation\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0729 - mae: 0.1366\n",
      "Model 2 Evaluation\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1041 - mae: 0.1802\n",
      "Model 3 Evaluation\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1072 - mae: 0.1500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1171061098575592, 0.1481107473373413]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate models\n",
    "print(\"Model 1 Evaluation\")\n",
    "model1.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Model 2 Evaluation\")\n",
    "model2.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Model 3 Evaluation\")\n",
    "model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "Model 1 R-squared: 0.9214994119977746\n",
      "Model 2 R-squared: 0.8840583824155741\n",
      "Model 3 R-squared: 0.837327309756317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R-squared for each model\n",
    "y_pred1 = model1.predict(X_test)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "y_pred3 = model3.predict(X_test)\n",
    "\n",
    "r2_model1 = r2_score(y_test, y_pred1)\n",
    "r2_model2 = r2_score(y_test, y_pred2)\n",
    "r2_model3 = r2_score(y_test, y_pred3)\n",
    "\n",
    "print(\"Model 1 R-squared:\", r2_model1)\n",
    "print(\"Model 2 R-squared:\", r2_model2)\n",
    "print(\"Model 3 R-squared:\", r2_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporte"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
